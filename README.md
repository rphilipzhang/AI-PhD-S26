# ü§ñ Artificial Intelligence for Business Research (Spring 2025)

<div align="center">

![Course Banner](https://img.shields.io/badge/DOTE%206635-Spring%202025-blue)
![Status](https://img.shields.io/badge/Status-Ongoing-yellow)
![PhD Level](https://img.shields.io/badge/Level-PhD-red)

</div>


- üìö [Scribed Lecture Notes](https://rphilipzhang.github.io/rphilipzhang/Scribed_Notes-AI-PhD-S25.pdf)
- üé• [Video Recording](https://docs.google.com/document/d/1J3OA4_QlxACGxiffoXjRhj7t4mV3KiHKOfeuVt48fsA/edit?usp=sharing) (You need to apply for the access.)

## üë• Teaching Team

| Role | Name & Contact |
|------|----------------|
| **Instructor** | [Renyu (Philip) Zhang](https://rphilipzhang.github.io/rphilipzhang/index.html)<br>Associate Professor, Department of Decisions, Operations and Technology, CUHK Business School <br>üìß philipzhang@cuhk.edu.hk<br>üìç @911 Cheng Yu Tung Building |
| **Teaching Assistant** | Leo Cao<br>Full-time TA, Department of Decisions, Operations and Technology, CUHK Business School<br>üìß yinglyucao@cuhk.edu.hk |
| **Tutorial Instructor** | [Xinyu Li](https://grad.bschool.cuhk.edu.hk/students/li-xinyu/)<br>PhD Candidate (Management Information Systems), CUHK Business School<br>üìß xinyu.li@link.cuhk.edu.hk |


## üìö Basic Information

- üåê Website: https://github.com/rphilipzhang/AI-PhD-S25
- ‚è∞ Time: Tuesday, 12:30pm-3:15pm (Jan 14 - Apr 15, 2025)
  - *Excluding: Jan 28 (Chinese New Year)*
- üìç Location: Wu Ho Man Yuen Building (WMY) **504**


## About

Welcome to the mono-repo of DOTE 6635: AI for Business Research at CUHK Business School! 

### üéØ Learning Objectives:

- üß† Gain fundamental understanding of ML/AI concepts and methods relevant to business research.
- üí° Explore applications of ML/AI in business research over the past decade.
- üöÄ Discover and nuture the taste of cutting-edge AI/ML technologies and their potential in your research domain.

[Download Syllabus](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/AI-PhD-Syllabus-S2025.pdf)

### Virtual Access
Need to join remotely? Use our Zoom link (please seek approval from Philip):
- üé• [Join Meeting](https://cuhk.zoom.us/j/91863445131?pwd=6Pq42Ud2f4n788LRANI2j6a2ivFoMX.1)
  - Meeting ID: 918 6344 5131
  - Passcode: 459761
 
### üõ†Ô∏è Course Resources

Most of the code in this course will be distributed through the [Google CoLab](https://colab.research.google.com/) cloud computing environment to avoid the incompatibility and version control issues on your local individual computer. On the other hand, you can always download the Jupyter Notebook from CoLab and run it your own computer.

- üìö The **Literature References** discussed in the slides can be found on [this document](https://docs.google.com/document/d/14cZNecp3yHjgAYeicCFTHCe2lunYmkRxoTEnngb25wA/edit?usp=sharing).
- üìì The **CoLab** files of this course can be found at [this folder](https://drive.google.com/drive/folders/1lYO4ni5B5AVkYZ3qVrVs2LoWxHProsxM?usp=sharing).
- üìä The **Google Sheet** to sign up for groups and group tasks can be found [here](https://docs.google.com/spreadsheets/d/1ffRNlSFqki4vomz5UN0OseFNEoEXBY5kptS79wmgWs4/edit?usp=sharing).
- üìù The overleaf template for scribing the lecture notes of this course can be found [here](https://www.overleaf.com/read/vjypshwbmnxr#a63c60).
- üî¨ The replication projects can be found [here](https://docs.google.com/document/d/1dpdvWGdaNWQVVg-osY7tNlv7HkksO66MTDAuIMJwvtI/edit?usp=sharing).
- üñ•Ô∏è The HPC Server compute resource of the CUHK DOT Department can be found [here](https://github.com/QiansiqiHu/DOT-server).


If you have any feedback on this course, please directly contact Philip at philipzhang@cuhk.edu.hk and we will try our best to address it.

## üìö Previous Offerings
- **üóÇÔ∏è GitHub Repos:** [Spring 2024@CUHK](https://github.com/rphilipzhang/AI-PhD-S24), [Summer 2024@SJTU Antai](https://github.com/rphilipzhang/AI-PhD-Antai-Su2024)
- **üé• Video Recordings (You need to apply for access):** [Spring 2024@CUHK](https://docs.google.com/document/d/1wUy9zWQHBI4gouM9x-xW0pqhqRD5WgLXPLRT9A1iCPA/edit?usp=sharing), [Summer 2024@SJTU Antai](https://docs.google.com/document/d/15nrUMEhW-Le3N8AJwxWrH1UFxWc0G1w2ZeGbbDwELQc/edit?usp=sharing)
- **üìù Scribed Notes:** [Spring 2024@CUHK](https://github.com/rphilipzhang/AI-PhD-S24/blob/main/Notes/Scribed_Notes-AI-PhD-S24.pdf)

## üìÖ Brief Schedule
Subject to modifications. All classes start at 12:30pm and end at 3:15pm.
|Session|Date |Topic|Key Words|
|:-------:|:-------------:|:----:|:-:|
|1|1.14|AI/ML in a Nutshell|Course Intro, Prediction in Biz Research|
|2|1.21|Intro to DL|ML Model Evaluations, DL Intro, Neural Nets|
|3|2.04|LLM (I)|DL Computations, Attention Mechanism| 
|4|2.11|LLM (II)|Transformer, ViT, DiT|
|5|2.18|LLM (III)| BERT, GPT|
|6|2.25|LLM (IV)|LLM Pre-training, DL Computations|
|7|3.04|LLM (V)|Post-training, Fine-tuning, RLHF, Test-Time Scaling, Inference, Quantization| 
|8|3.11|LLM (VI)| Agentic AI, AI as Human Simulators, Applications in Business Research| 
|9|3.18|Causal (I)|Causal Inference Intro, RCT|
|10|3.25|Causal (II)|IPW, AIPW|
|11|4.01|Causal (III)|Partial Linear Models, Double Machine Learning|
|12|4.08|Causal (IV)|Double Machine Learning, Neyman Orthogonality|
|13|4.15|Causal (V)|Heterogeneous Treatment Effect, Causal Tree, Causal Forest, Course Wrap-up|
|13+|Summer|Course Remake|Synthetic Control, Matrix Completion, LLM x Causal Inference, Interference, etc.|

## üìÖ Important Dates

All problem sets are due at 12:30pm right before class.

|Date| Time|Event|Note|
|:--:|:-:|:---:|:--:|
|1.15| 11:59pm|[Group Sign-Ups](https://docs.google.com/spreadsheets/d/1ffRNlSFqki4vomz5UN0OseFNEoEXBY5kptS79wmgWs4/edit?usp=sharing)|Each group has at most two students.|
|1.17| 7:00pm-9:00pm|Python Tutorial|Given by Xinyu Li, [Python Tutorial CoLab](https://drive.google.com/drive/folders/19iL1wYT2zeaYeIY7QyxQz7QQsZGrq7Nk?usp=sharing)|
|1.24| 7:00pm-9:00pm|[PyTorch](https://pytorch.org/docs/stable/nn.html) and [DOT HPC Server](https://github.com/QiansiqiHu/DOT-server) Tutorial|Given by Xinyu Li, [PyTorch Tutorial CoLab](https://drive.google.com/drive/folders/19iL1wYT2zeaYeIY7QyxQz7QQsZGrq7Nk?usp=sharing)|
|3.04|9:00am-6:00pm|Final Project Discussion|Please schedule a meeting with Philip.|
|3.11| 12:30pm|Final Project Proposal|1-page maximum|
|4.30| 11:59pm|Scribed Lecture Notes|Overleaf link|
|5.11|11:59pm|Project Paper, Slides, and Code|Paper page limit: 10| 


## üìö Useful External Resources
Find more on the [Syllabus](https://github.com/rphilipzhang/AI-PhD-S24/blob/main/AI-PhD-Syllabus-S2025.pdf) and [the literature references](https://docs.google.com/document/d/14cZNecp3yHjgAYeicCFTHCe2lunYmkRxoTEnngb25wA/edit?usp=sharing) discussed in the slides.

- üìñ **Books**:
  - **Foundations**: [ESL](https://hastie.su.domains/ElemStatLearn/), [DL](https://www.deeplearningbook.org/), [Dive into DL](https://d2l.ai/), [RL: An Introduction](https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf)
  - **Advanced Topics**: [ML Fairness](https://fairmlbook.org/), [Applied Causal Inference Powered by ML and AI](https://causalml-book.org/), [Causal Inference: A Statistical Learning Approach](https://web.stanford.edu/~swager/causal_inf_book.pdf), [Introduction to Causal Inference from a Machine Learning Perspective](https://www.bradyneal.com/Introduction_to_Causal_Inference-Dec17_2020-Neal.pdf)

- üéì **Courses**:
  - **Foundations**: [ML Intro by Andrew Ng](https://www.coursera.org/specializations/machine-learning-introduction), [DL Intro by Andrew Ng](https://www.coursera.org/specializations/deep-learning), [Generative AI by Andrew Ng](https://www.deeplearning.ai/short-courses/), [Introduction to Causal Inference by Brady Neal](https://www.bradyneal.com/causal-inference-course)
  - **Advanced Technologies**: [NLP (CS224N) by Chris Manning](https://web.stanford.edu/class/cs224n/), [CV (CS231N) by Fei-Fei Li](http://cs231n.stanford.edu/), [Deep Unsupervised Learning by Pieter Abbeel](https://sites.google.com/view/berkeley-cs294-158-sp24/home), [DLR by Sergey Levine](https://rail.eecs.berkeley.edu/deeprlcourse/), [DL Theory by Matus Telgarsky](https://mjt.cs.illinois.edu/courses/dlt-f22/), [LLM by Danqi Chen](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/), [LLM from Scratch (CS336) by Persy Liang](https://stanford-cs336.github.io/spring2024/), [Efficient Deep Learning Computing by Song Han](https://hanlab.mit.edu/courses/2024-fall-65940), [Deep Generative Models by Kaiming He](https://mit-6s978.github.io/), [LLM Agents by Dawn Song](https://llmagents-learning.org/f24), [Advanced LLM Agents by Dawn Song](https://llmagents-learning.org/sp25), [Data, Learning, and Algorithms by Tengyuan Liang](https://tyliang.github.io/courses/dla/), [Hands-on DRL by Weinan Zhang, Jian Shen, and Yu Yong (in Chinese)](https://hrl.boyuai.com/), [Understanding LLM: Foundations and Safety by Dawn Song](https://rdi.berkeley.edu/understanding_llms/s24)
  - **Biz/Econ Applications of AI**: [Machine Learning and Big Data by Melissa Dell and Matthew Harding](https://www.aeaweb.org/conference/cont-ed/2023-webcasts), [Digital Economics and the Economics of AI by Martin Beraja, Chiara Farronato, Avi Goldfarb, and Catherine Tucker](https://www.aeaweb.org/content/file?id=19707), [Generative AI and Causal Inference with Texts](https://dashing-cormorant-358.notion.site/QST-IS-911-Generative-AI-and-Causal-Inference-with-Text-454d1f068a7f46ac9bb29c584a8ced3b), [NLP for Computational Social Science by Diyi Yang](https://web.stanford.edu/class/cs224c/)

- üí° **Tutorials and Blogs**:
  - [GitHub of Andrej Karpathy](https://github.com/karpathy), [Blog of Lilian Weng](https://lilianweng.github.io/), [Double Machine Learning Package Documentation](https://docs.doubleml.org/stable/index.html), [Causality and Deep Learning (ICML 2022 Tutorial)](https://sites.google.com/view/causalityanddeeplearning/start), [Causal Inference and Machine Learning (KDD 2021 Tutorial)](https://causal-machine-learning.github.io/kdd2021-tutorial/), [Online Causal Inference Seminar](https://sites.google.com/view/ocis/), [Training a Chinese LLM from Scratch (in Chinese)](https://github.com/zhanshijinwat/Steel-LLM), [Physics of Language Models (ICML 2024 Tutorial)](https://physics.allen-zhu.com/home), [Counterfactual Learning and Evaluation for Recommender Systems: Foundations, Implementations, and Recent Advances (RecSys 2021 Tutorial)](https://sites.google.com/cornell.edu/recsys2021tutorial), [Language Agents: Foundations, Prospects, and Risks (EMNLP 2024 Tutorial)](https://language-agent-tutorial.github.io/), [GitHub Repo: Upgrading Cursor to Devin](https://github.com/grapeot/devin.cursorrules) 



## üìã Detailed Schedule

The following schedule is tentative and subject to changes.

### üìö Session 1. Artificial Intelligence and Machine Learning in a Nutshell (Jan/14/2025)
- üîë **Keywords**: Course Introduction, Prediction in Biz Research, Basic ML Models
- üìä **Slides**: [Course Intro](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-1-Intro.pdf), [Prediction](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-2-Prediction.pdf), [ML Intro](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-3-Intro2ML.pdf)
- üíª **CoLab Notebook Demos**: [Bootstrap](https://colab.research.google.com/drive/1iAGJTOYY7rtvrGDCN1sPqeMUzdfJqYK3?usp=drive_link), [k-Nearest Neighbors](https://colab.research.google.com/drive/1Uzi3cosnnY3NSpNmosawlNIsEkEIzO_u?usp=sharing), [Decision Tree](https://colab.research.google.com/drive/1rqI5LA2m_u7fxsVgCk_dQqz1nFU00iXS?usp=sharing), [Random Forest](https://colab.research.google.com/drive/1hYGZMVPs-kKNt-faAcwULUSdpJTRLe2K?usp=sharing), [Gradient Boosting Tree](https://colab.research.google.com/drive/17IiebxpvjiFXYjUkejjry1cNNrMjUJDN?usp=sharing)
- ‚úçÔ∏è **Homework**: [Problem Set 1 - Housing Price Prediction](https://colab.research.google.com/drive/1EDWWfXRENzztcUBgSQ-GB3KOdRRfgfRw), due at 12:30pm, Feb/4/2025
- üéì **Online Python Tutorial**: [Python Tutorial CoLab](https://drive.google.com/drive/folders/19iL1wYT2zeaYeIY7QyxQz7QQsZGrq7Nk?usp=sharing), 7:00pm-9:00pm, Jan/17/2025 (Friday), given by Xinyu Li, xinyu.li@link.cuhk.edu.hk. [Zoom Link](https://cuhk.zoom.us/j/93944864920?pwd=KAPcowZbwJj0YYOHertGqyKChCP0bv.1), Meeting ID: 939 4486 4920, Passcode: 456911
- üìö **References**:
    - *The Elements of Statistical Learning* (2nd Edition), 2009, by Trevor Hastie, Robert Tibshirani, Jerome Friedman, [link to ESL](https://hastie.su.domains/ElemStatLearn/).
    - *Probabilistic Machine Learning: An Introduction*, 2022, by Kevin Murphy, [link to PML](https://probml.github.io/pml-book/book1.html).
    - Mullainathan, Sendhil, and Jann Spiess. 2017. Machine learning: an applied econometric approach. *Journal of Economic Perspectives* 31(2): 87-106.
    - Athey, Susan, and Guido W. Imbens. 2019. Machine learning methods that economists should know about. *Annual Review of Economics* 11: 685-725.
    - Kleinberg, Jon, Jens Ludwig, Sendhil Mullainathan, and Ziad Obermeyer. 2015. Prediction policy problems. *American Economic Review* 105(5): 491-495.
    - Hofman, Jake M., et al. 2021. Integrating explanation and prediction in computational social science. *Nature* 595.7866: 181-188.
    - Bastani, Hamsa, Dennis Zhang, and Heng Zhang. 2022. Applied machine learning in operations management. *Innovative Technology at the Interface of Finance and Operations*. Springer: 189-222.
    - Kelly, Brian, and Dacheng Xiu. 2023. Financial machine learning, *SSRN*, [link to the paper](https://ssrn.com/abstract=4501707).   
    - [The Bitter Lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html), by Rich Sutton, which develops so far the most critical insight of AI: "The biggest lesson that can be read from 70 years of AI research is that general methods that leverage computation are ultimately the most effective, and by a large margin."
    - Chatpers 1 & 3.2, [Scribed Notes of Spring 2024 Course Offering](https://github.com/rphilipzhang/AI-PhD-S24/blob/main/Notes/Scribed_Notes-AI-PhD-S24.pdf).

### üìö Session 2. Model Selection and Deep Learning Basics (Jan/21/2025)
- üîë **Keywords**: Bias-Variance Trade-off, Cross Validation, Bootstrap, Neural Nets, Computational Issues of Deep Learning
- üìä **Slides**: [ML Intro](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-3-Intro2ML.pdf), [DL Intro](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-4-Intro2DL.pdf)
- üíª **CoLab Notebook Demos**: [Gradient Descent](https://colab.research.google.com/drive/1bgwzNd0u2cCshELSxxg-9QMA2OMrXEui), [Chain Rule](https://colab.research.google.com/drive/1gzYErH1tAOWaKb-sqCUgNLNQ8Ww4iV7t), [He Innitialization](https://colab.research.google.com/drive/1KuZHvgAVA2nKSkVdVsWzSCKgOoRuX_hF)
- ‚úçÔ∏è **Homework**: [Problem Set 2: Implementing Neural Nets](https://colab.research.google.com/drive/1mwte7tn0R68Hj3ZZCvUA5RoUqcdQpja5), due at 12:30pm, Feb/11/2025
- üéì **Online PyTorch and [DOT HPC Server](https://github.com/QiansiqiHu/DOT-server) Tutorial**: [PyTorch Tutorial CoLab](https://drive.google.com/drive/folders/19iL1wYT2zeaYeIY7QyxQz7QQsZGrq7Nk?usp=sharing), 7:00pm-9:00pm, Jan/24/2025 (Friday), given by Xinyu Li, xinyu.li@link.cuhk.edu.hk. [Zoom Link](https://cuhk.zoom.us/j/93944864920?pwd=KAPcowZbwJj0YYOHertGqyKChCP0bv.1), Meeting ID: 939 4486 4920, Passcode: 456911
- üìö **References**:
    - *Deep Learning*, 2016, by Ian Goodfellow, Yoshua Bengio and Aaron Courville, [link to DL](https://www.deeplearningbook.org/).
    - *Dive into Deep Learning* (2nd Edition), 2023, by Aston Zhang, Zack Lipton, Mu Li, and Alex J. Smola, [link to d2dl](https://d2l.ai/).
    - *Probabilistic Machine Learning: Advanced Topics*, 2023, by Kevin Murphy, [link to PML2](https://probml.github.io/pml-book/book2.html).
    - *Deep Learning with PyTorch*, 2020, by Eli Stevens, Luca Antiga, and Thomas Viehmann.
    - Dell, Mellissa. 2024. Deep learning for economists. *Journal of Economic Literature*, forthcoming, [link to the paper](https://arxiv.org/abs/2407.15339).
    - Davies, A., Veliƒçkoviƒá, P., Buesing, L., Blackwell, S., Zheng, D., Toma≈°ev, N., Tanburn, R., Battaglia, P., Blundell, C., Juh√°sz, A. and Lackenby, M., 2021. Advancing mathematics by guiding human intuition with AI. *Nature*, 600(7887), pp.70-74.
    - Ye, Z., Zhang, Z., Zhang, D., Zhang, H. and Zhang, R.P., 2023. Deep-Learning-Based Causal Inference for Large-Scale Combinatorial Experiments: Theory and Empirical Evidence. Available at *SSRN* 4375327, [link to the paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4375327).
    - Luyang Chen, Markus Pelger, Jason Zhu (2023) Deep Learning in Asset Pricing. *Management Science* 70(2):714-750.
    - Wang, Z., Gao, R. and Li, S. 2024. Neural-Network Mixed Logit Choice Model: Statistical and Optimality Guarantees. *Working paper*.
    - [Why Does Adam Work So Well? (in Chinese)](https://www.zhihu.com/question/323747423/answer/2576604040), [Overview of gradient descent algorithms](https://arxiv.org/pdf/1609.04747)
    - Chatpers 1 & 2, [Scribed Notes of Spring 2024 Course Offering](https://github.com/rphilipzhang/AI-PhD-S24/blob/main/Notes/Scribed_Notes-AI-PhD-S24.pdf).

### üìö Session 3. Deep Learning Computations and Attention Mechanism (Feb/4/2025)
- üîë **Keywords**: Deep Learning Computations, Seq2Seq, Attention Mechanism, Transformer
- üìä **Slides**: [What's New](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-0-WhatsNew.pdf), [DL Intro](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-4-Intro2DL.pdf), [Transformer](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-5-Transformers.pdf)
- üíª **CoLab Notebook Demos**: [Dropout](https://colab.research.google.com/drive/14VIl6_JokegSFRSUgaxX8Xi8hvZY-GRn), [Micrograd](https://colab.research.google.com/drive/1T_ZwQdzSpXCDR5cwt_0eH1wUvWNiMGAJ), [Attention Mechanism](https://colab.research.google.com/drive/11Lx075g2elZa1Vbcbbcx1YfGuQdXLXws)
- ‚úçÔ∏è **Homework**: [Problem Set 2: Implementing Neural Nets](https://colab.research.google.com/drive/1mwte7tn0R68Hj3ZZCvUA5RoUqcdQpja5), due at 12:30pm, Feb/11/2025
- üìù **Presentation of Replication Project**: By Jiaci Yi and Yachong Wang
    - Gui, G. and Toubia, O., 2023. The challenge of using LLMs to simulate human behavior: A causal inference perspective. *arXiv:2312.15524*. [Link to the paper](https://arxiv.org/abs/2312.15524). [Replication Report, Code, and Slides](https://docs.google.com/spreadsheets/d/1ffRNlSFqki4vomz5UN0OseFNEoEXBY5kptS79wmgWs4/edit?gid=422252848#gid=422252848). 
- üìö **References**:
    - *Deep Learning*, 2016, by Ian Goodfellow, Yoshua Bengio and Aaron Courville, [link to DL](https://www.deeplearningbook.org/).
    - *Dive into Deep Learning* (2nd Edition), 2023, by Aston Zhang, Zack Lipton, Mu Li, and Alex J. Smola, [link to d2dl](https://d2l.ai/).
    - Dell, Mellissa. 2024. Deep learning for economists. *Journal of Economic Literature*, forthcoming, [link to the paper](https://arxiv.org/abs/2407.15339).
    - Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. 2014. Sequence to sequence learning with neural networks. *Advances in neural information processing systems*, 27.
    - Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural machine translation by jointly learning to align and translate. *ICLR*
    - Lecture Notes and Slides for CS224n: Natural Language Processing with Deep Learning, by Christopher D. Manning, Diyi Yang, and Tatsunori Hashimoto. [Link to CS224n](https://web.stanford.edu/class/cs224n/).
    - [Parameter Initialization and Batch Normalization (in Chinese)](https://zhuanlan.zhihu.com/p/25110150), [GPU Comparisons](https://bizon-tech.com/gpu-benchmarks/NVIDIA-A100-80-GB-(PCIe)-vs-NVIDIA-H100-(PCIe)-vs-NVIDIA-RTX-6000-Ada/624vs632vs640), [GitHub Repo for Micrograd](https://github.com/karpathy/micrograd) by [Andrej Karpathy](https://github.com/karpathy).
    - [RNN and LSTM Visualizations](https://colah.github.io/posts/2015-08-Understanding-LSTMs/), [PyTorch's Tutorial of Seq2Seq for Machine Translation](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html).
    - Chatpers 2 & 6, [Scribed Notes of Spring 2024 Course Offering](https://github.com/rphilipzhang/AI-PhD-S24/blob/main/Notes/Scribed_Notes-AI-PhD-S24.pdf).
    - [Handwritten Notes](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Notes/250204.pdf)

### üìö Session 4. Transformer (Feb/11/2025)
- üîë **Keywords**: Transformer, ViT, DiT, Decision Transformer
- üìä **Slides**: [What's New](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-0-WhatsNew.pdf), [Transformer](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-5-Transformers.pdf)
- üíª **CoLab Notebook Demos**: [Attention Mechanism](https://colab.research.google.com/drive/11Lx075g2elZa1Vbcbbcx1YfGuQdXLXws), [Transformer](https://colab.research.google.com/drive/1LKHCItyYk94UfZMMWWcoD81CVqEWMY5a)
- ‚úçÔ∏è **Homework**: [Problem Set 3: Sentiment Analysis with BERT](https://colab.research.google.com/drive/1mmdGC2xpC8wrotfn2ZK36vM0kCH0Z9Lj?usp=drive_link), due at 12:30pm, Mar/4/2025
- üìù **Presentation of Replication Project**: By Xiqing Qin and Yuxin Chen
    - Manning, B.S., Zhu, K. and Horton, J.J., 2024. Automated social science: Language models as scientists and subjects (No. w32381). *National Bureau of Economic Research*. [Link to the paper](https://www.nber.org/papers/w32381), [link to GitHub Repo](https://github.com/KeHang-Zhu/lm-automated-social-science/). [Replication Report, Code, and Slides](https://docs.google.com/spreadsheets/d/1ffRNlSFqki4vomz5UN0OseFNEoEXBY5kptS79wmgWs4/edit?gid=422252848#gid=422252848). 
- üìö **References**:
    - Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... and Polosukhin, I. (2017). Attention is all you need. *Advances in neural information processing systems*, 30.
    - Qi, Meng, Yuanyuan Shi, Yongzhi Qi, Chenxin Ma, Rong Yuan, Di Wu, Zuo-Jun (Max) Shen. 2023. A Practical End-to-End Inventory Management Model with Deep Learning. *Management Science*, 69(2): 759-773.
    - Sarzynska-Wawer, Justyna, Aleksander Wawer, Aleksandra Pawlak, Julia Szymanowska, Izabela Stefaniak, Michal Jarkiewicz, and Lukasz Okruszek. 2021. Detecting formal thought disorder by deep contextualized word representations. *Psychiatry Research*, 304, 114135.
    - Hansen, Stephen, Peter J. Lambert, Nicholas Bloom, Steven J. Davis, Raffaella Sadun, and Bledi Taska. 2023. Remote work across jobs, companies, and space (No. w31007). *National Bureau of Economic Research*.
    - Chapter 11, *Dive into Deep Learning* (2nd Edition), 2023, by Aston Zhang, Zack Lipton, Mu Li, and Alex J. Smola, [link to d2dl](https://d2l.ai/).
    - Lecture Notes and Slides for CS224n: Natural Language Processing with Deep Learning, by Christopher D. Manning, Diyi Yang, and Tatsunori Hashimoto. [Link to CS224n](https://web.stanford.edu/class/cs224n/).
    - Part 2, Slides for COS 597G: Understanding Large Language Models, by Danqi Chen. [Link to COS 597G](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/)
    - [Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/), [Transformer from Scratch](https://peterbloem.nl/blog/transformers) with the [Code on GitHub](https://github.com/pbloem/former).
    - Andrej Karpathy's Lecture: [Deep Dive into LLM](https://www.youtube.com/watch?v=7xTGNNLPyMI)
    - Chatpers 7 [Scribed Notes of Spring 2024 Course Offering](https://github.com/rphilipzhang/AI-PhD-S24/blob/main/Notes/Scribed_Notes-AI-PhD-S24.pdf).
    - [Handwritten Notes](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Notes/250211.pdf)

### üìö Session 5. LLM Pretraining (Feb/18/2025)
- üîë **Keywords**: Pretraining, Scaling Law, BERT, GPT, DeepSeek
- üìä **Slides**: [What's New](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-0-WhatsNew.pdf), [Pretraining](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-6-Pretraining.pdf)
- üíª **CoLab Notebook Demos**: [Attention Mechanism](https://colab.research.google.com/drive/11Lx075g2elZa1Vbcbbcx1YfGuQdXLXws), [Transformer](https://colab.research.google.com/drive/1LKHCItyYk94UfZMMWWcoD81CVqEWMY5a)
- ‚úçÔ∏è **Homework**: [Problem Set 3: Sentiment Analysis with BERT](https://colab.research.google.com/drive/1mmdGC2xpC8wrotfn2ZK36vM0kCH0Z9Lj?usp=drive_link), due at 12:30pm, Mar/4/2025
- üìù **Presentation of Replication Project**: By Guohao Li and Jin Wang
    - Li, P., Castelo, N., Katona, Z. and Sarvary, M., 2024. Frontiers: Determining the validity of large language models for automated perceptual analysis. Marketing Science, 43(2), pp.254-266. [Link to the paper](https://pubsonline.informs.org/doi/abs/10.1287/mksc.2023.0454?casa_token=T4ZJMw7WFCAAAAAA%3ALx3qRvPDX_Gou1BtOEIgYSH0_ayYLgtNDsUpK_MOakdxlbfCqabiWnxuRk2Oa7pFT4_8-6h7uZXNUQ&journalCode=mksc). [Link to the replication package](https://services.informs.org/dataset/mksc/download.php?doi=mksc.2023.0454). [Replication Report, Code, and Slides](https://docs.google.com/spreadsheets/d/1ffRNlSFqki4vomz5UN0OseFNEoEXBY5kptS79wmgWs4/edit?gid=422252848#gid=422252848).
- üìö **References**:
    - Devlin, Jacob, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. 2018. BERT: Pre-training of deep bidirectional transformers for language understanding. *ArXiv preprint* arXiv:1810.04805. [GitHub Repo](https://github.com/google-research/bert)
    - Radford, Alec, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018. Improving language understanding by generative pre-training, (GPT-1) [PDF link](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf), [GitHub Repo](https://github.com/openai/finetune-transformer-lm)
    - Radford, Alec, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever. 2019. Language models are unsupervised multitask learners. OpenAI blog, 1(8), 9. (GPT-2) [PDF Link](https://insightcivic.s3.us-east-1.amazonaws.com/language-models.pdf), [GitHub Repo](https://github.com/openai/gpt-2)
    - Brown, Tom, et al. 2020. Language models are few-shot learners. *Advances in neural information processing systems*, 33, 1877-1901. (GPT-3) [GitHub Repo](https://github.com/openai/gpt-3)
    - DeepSeek-AI, 2024. Deepseek-V3 Technical Report. *arXiv:2412.19437*. [GitHub Repo](https://github.com/deepseek-ai/DeepSeek-V3)
    - Huang, Allen H., Hui Wang, and Yi Yang. 2023. FinBERT: A large language model for extracting information from financial text. *Contemporary Accounting Research*, 40(2): 806-841. (FinBERT) [GitHub Repo](https://github.com/yya518/FinBERT)
    - Gorodnichenko, Y., Pham, T. and Talavera, O., 2023. The voice of monetary policy. American Economic Review, 113(2), pp.548-584.
    - Reisenbichler, Martin, Thomas Reutterer, David A. Schweidel, and Daniel Dan. 2022. Frontiers: Supporting content marketing with natural language generation. *Marketing Science*, **41**(3): 441-452.
    - Books, Notes, and Courses: Chapter 11.9 of [*Dive into Deep Learning*](https://d2l.ai/), Part 9 of [CS224N: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/cs224n/), Part 2 & 4 of [COS 597G: Understanding Large Language Models](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/), Part 3 & 4 of [CS336: Large Language Models from Scratch](https://stanford-cs336.github.io/spring2024/index.html), Chatper 8 of [Scribed Notes for Spring 2024 Course Offering](https://github.com/rphilipzhang/AI-PhD-S24/blob/main/Notes/Scribed_Notes-AI-PhD-S24.pdf), [Handwritten Notes](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Notes/250218.pdf).
    - Andrej Karpathy's Lectures: [Build GPT-2 (124M) from Scratch](https://www.youtube.com/watch?v=l8pRSuU81PU) [GitHub Repo for NanoGPT](https://github.com/karpathy/build-nanogpt/tree/master), [Deep Dive into LLM](https://www.youtube.com/watch?v=7xTGNNLPyMI), [Build the GPT Tokenizer](https://www.youtube.com/watch?v=zduSFxRajkE)
    - Miscellaneous Resources: [CS224n, Hugging Face ü§ó Tutorial](https://colab.research.google.com/drive/13r94i6Fh4oYf-eJRSi7S_y_cen5NYkBm?usp=sharing), [A Visual Guide to BERT](https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/), [LLM Visualization](https://bbycroft.net/llm), [How GPT-3 Works](https://jalammar.github.io/how-gpt3-works-visualizations-animations/), [Video on DeepSeek MoE](https://www.youtube.com/watch?v=P7txFafuUOE), [TikTokenizer](https://tiktokenizer.vercel.app/), [Inference with Base LLM](https://app.hyperbolic.xyz/)

### üìö Session 6. LLM Pretraining & Posttraining (Feb/25/2025)
- üîë **Keywords**: Posttraining, Instruct GPT, SFT, RLHF, DPO, Test-Time Scaling, Knowledge Distillation
- üìä **Slides**: [What's New](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-0-WhatsNew.pdf), [Pretraining](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-6-Pretraining.pdf), [Posttraining](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-7-Posttraining.pdf)
- üíª **CoLab Notebook Demos**: [BERT API @ Hugging Face ü§ó](https://colab.research.google.com/drive/1erSNbevWi0o7Kb6G3_6GiTqCE4VfEjbe?usp=drive_link), [BERT Finetuning](https://colab.research.google.com/drive/1K1KtgK8cFccscs0wyzU_-7QtsUnS2Wkk?usp=sharing)
- ‚úçÔ∏è **Homework**: [Problem Set 4: Finetuning LLM](https://colab.research.google.com/drive/15kAfanD_W-CTOZnyQBjGHwLTlMfGcPgp?usp=sharing), due at 12:30pm, Mar/18/2025
- üìù **Presentation of Replication Project**: By Di Wu and Chuchu Sun
    - Radford, Alec, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever. 2019. Language models are unsupervised multitask learners. OpenAI blog, 1(8), 9. (GPT-2) [PDF Link](https://insightcivic.s3.us-east-1.amazonaws.com/language-models.pdf), [GitHub Repo](https://github.com/karpathy/build-nanogpt), [Replication Report, Code, and Slides](https://docs.google.com/spreadsheets/d/1ffRNlSFqki4vomz5UN0OseFNEoEXBY5kptS79wmgWs4/edit?gid=422252848#gid=422252848).
- üìö **References**:
    - Ouyang, Long, et al. 2022. Training language models to follow instructions with human feedback. *Advances in Neural Information Processing Systems*, **35**, 27730-27744.
    - Chu, T., Zhai, Y., Yang, J., Tong, S., Xie, S., Schuurmans, D., Le, Q.V., Levine, S. and Ma, Y., 2025. Sft memorizes, rl generalizes: A comparative study of foundation model post-training. *arXiv preprint arXiv:2501.17161*.
    - Wei, Jason, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. *Advances in Neural Information Processing Systems*, **35**, 24824-24837.
    - Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T., Cao, Y. and Narasimhan, K., 2023. Tree of thoughts: Deliberate problem solving with large language models. *Advances in neural information processing systems*, **36**, pp.11809-11822.
    - Brynjolfsson, E., Li, D. and Raymond, L., 2025. Generative AI at work. *The Quarterly Journal of Economics*, p.qjae044.
    - Hinton, G., Vinyals, O. and Dean, J., 2015. Distilling the knowledge in a neural network. *arXiv preprint arXiv:1503.02531*.
    - Books, Notes, and Courses: Part 10 of [CS224N: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/cs224n/), [Talk @ Stanford by Barret Zoph and John Schulman](https://docs.google.com/presentation/d/11KWCKUORnPpVMSY6vXgBeFSWo7fJcuGQ9yuR6vC1pzE), Part 3, 4, 9 & 10 of [CS336: Large Language Models from Scratch](https://stanford-cs336.github.io/spring2024/index.html), Part 9 & 14 of [MIT 6.5940: TinyML and Efficient Deep Learning Computing](https://hanlab.mit.edu/courses/2024-fall-65940), Chatper 9 of [Scribed Notes for Spring 2024 Course Offering](https://github.com/rphilipzhang/AI-PhD-S24/blob/main/Notes/Scribed_Notes-AI-PhD-S24.pdf), [Handwritten Notes](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Notes/250225.pdf).
    - Andrej Karpathy's Lectures: [Build GPT-2 (124M) from Scratch](https://www.youtube.com/watch?v=l8pRSuU81PU) [GitHub Repo for NanoGPT](https://github.com/karpathy/build-nanogpt/tree/master), [Deep Dive into LLM](https://www.youtube.com/watch?v=7xTGNNLPyMI), [Build the GPT Tokenizer](https://www.youtube.com/watch?v=zduSFxRajkE)
    - Miscellaneous Resources: [CS224n, Hugging Face ü§ó Tutorial](https://colab.research.google.com/drive/13r94i6Fh4oYf-eJRSi7S_y_cen5NYkBm?usp=sharing), [LLM Visualization](https://bbycroft.net/llm), [How GPT-3 Works](https://jalammar.github.io/how-gpt3-works-visualizations-animations/), [Video on DeepSeek MoE](https://www.youtube.com/watch?v=P7txFafuUOE), [Video on DeekSeep Native Sparse Attention](https://www.bilibili.com/video/BV1bCADe4Eyf), [TikTokenizer](https://tiktokenizer.vercel.app/), [Inference with Base LLM](https://app.hyperbolic.xyz/)

### üìö Session 7. LLM Posttraining & Inference (Mar/4/2025)
- üîë **Keywords**: Posttraining, SFT, PEFT, RLHF, DPO
- üìä **Slides**: [What's New](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-0-WhatsNew.pdf), [What's Next](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-0.5-Announcement.pdf), [Posttraining](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-7-Posttraining.pdf)
- üíª **CoLab Notebook Demos**: [LLM Finetuning](https://colab.research.google.com/drive/1xNB0U0_qARcNbhO-6tawBBQ-GKsSqPc2?usp=sharing), [Quantization](https://colab.research.google.com/drive/1XSeaUmIaDRDMybgNeqz-APmGBq4r8np8?usp=sharing)
- ‚úçÔ∏è **Homework**: [Problem Set 4: Finetuning LLM](https://colab.research.google.com/drive/15kAfanD_W-CTOZnyQBjGHwLTlMfGcPgp?usp=sharing), due at 12:30pm, Mar/18/2025
- üìù **No Presentation of Replication Project in This Week**.
- üìö **References**:
    - Chu, T., Zhai, Y., Yang, J., Tong, S., Xie, S., Schuurmans, D., Le, Q.V., Levine, S. and Ma, Y., 2025. Sft memorizes, rl generalizes: A comparative study of foundation model post-training. *arXiv preprint arXiv:2501.17161*.
    - Wei, Jason, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. *Advances in Neural Information Processing Systems*, **35**, 24824-24837.
    - Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T., Cao, Y. and Narasimhan, K., 2023. Tree of thoughts: Deliberate problem solving with large language models. *Advances in neural information processing systems*, **36**, pp.11809-11822.
    - Brynjolfsson, E., Li, D. and Raymond, L., 2025. Generative AI at work. *The Quarterly Journal of Economics*, p.qjae044.
    - Hinton, G., Vinyals, O. and Dean, J., 2015. Distilling the knowledge in a neural network. *arXiv preprint arXiv:1503.02531*.
    - Muennighoff, N., Yang, Z., Shi, W., Li, X.L., Fei-Fei, L., Hajishirzi, H., Zettlemoyer, L., Liang, P., Cand√®s, E. and Hashimoto, T., 2025. s1: Simple test-time scaling. *arXiv preprint arXiv:2501.19393*.
    - Books, Notes, and Courses: Part 10 & 11 of [CS224N: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/cs224n/), [Talk @ Stanford by Barret Zoph and John Schulman](https://docs.google.com/presentation/d/11KWCKUORnPpVMSY6vXgBeFSWo7fJcuGQ9yuR6vC1pzE), Part 15 & 16 of [CS336: Large Language Models from Scratch](https://stanford-cs336.github.io/spring2024/index.html), Part 5, 6, 9 & 14 of [MIT 6.5940: TinyML and Efficient Deep Learning Computing](https://hanlab.mit.edu/courses/2024-fall-65940), [Finetuning LLMs](https://learn.deeplearning.ai/courses/finetuning-large-language-models), [Quantization Fundamentals](https://learn.deeplearning.ai/courses/quantization-fundamentals), Chatper 9 of [Scribed Notes for Spring 2024 Course Offering](https://github.com/rphilipzhang/AI-PhD-S24/blob/main/Notes/Scribed_Notes-AI-PhD-S24.pdf), [Handwritten Note](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Notes/250304.pdf).
    - Andrej Karpathy's Lectures: [Build GPT-2 (124M) from Scratch](https://www.youtube.com/watch?v=l8pRSuU81PU) [GitHub Repo for NanoGPT](https://github.com/karpathy/build-nanogpt/tree/master), [Deep Dive into LLM](https://www.youtube.com/watch?v=7xTGNNLPyMI), [How to Use LLM](https://www.youtube.com/watch?v=EWvNQjAaOHw), [Build the GPT Tokenizer](https://www.youtube.com/watch?v=zduSFxRajkE)
    - Miscellaneous Resources: [Video on DeepSeek R1](https://www.youtube.com/watch?v=tRuN8xYdETs), [Video on DeekSeep MLA](https://www.bilibili.com/video/BV1HqFQezEMt/), [Approximating KL Divergence](http://joschu.net/blog/kl-approx.html), [DeepSeek Open-Infra Repo](https://github.com/deepseek-ai/open-infra-index)

### üìö Session 8. LLM Inference and as Research Tools (Mar/11/2025)
- üîë **Keywords**: Test-Time Scaling, Knowledge Distillation, Inference, Quantization, LLM Evaluations, LLM Agents
- üìä **Slides**: [What's New](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-0-WhatsNew.pdf), [What's Next](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-0.5-Announcement.pdf), [Posttraining](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-7-Posttraining.pdf), [Inference](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-8-Inference.pdf), [Research Tools](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-9-LLM-Research-Tools.pdf)
- üíª **CoLab Notebook Demos**: [Quantization](https://colab.research.google.com/drive/1XSeaUmIaDRDMybgNeqz-APmGBq4r8np8?usp=sharing)
- ‚úçÔ∏è **Homework**: [Problem Set 4: Finetuning LLM](https://colab.research.google.com/drive/15kAfanD_W-CTOZnyQBjGHwLTlMfGcPgp?usp=sharing), due at 12:30pm, Mar/18/2025
- üìù **Presentation of Replication Project**: By Tao Wang and Zhe Liu
    - Jens Ludwig, Sendhil Mullainathan, Machine Learning as a Tool for Hypothesis Generation, *The Quarterly Journal of Economics*, Volume 139, Issue 2, May 2024, Pages 751‚Äì827, [link to the paper](https://doi.org/10.1093/qje/qjad055), [Replication Report, Code, and Slides](https://docs.google.com/spreadsheets/d/1ffRNlSFqki4vomz5UN0OseFNEoEXBY5kptS79wmgWs4/edit?gid=422252848#gid=422252848).
- üìö **References**:
    - Ouyang, Long, et al. 2022. Training language models to follow instructions with human feedback. *Advances in Neural Information Processing Systems*, **35**, 27730-27744.
    - Chu, T., Zhai, Y., Yang, J., Tong, S., Xie, S., Schuurmans, D., Le, Q.V., Levine, S. and Ma, Y., 2025. Sft memorizes, rl generalizes: A comparative study of foundation model post-training. *arXiv preprint arXiv:2501.17161*.
    - Wei, Jason, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. *Advances in Neural Information Processing Systems*, **35**, 24824-24837.
    - Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T., Cao, Y. and Narasimhan, K., 2023. Tree of thoughts: Deliberate problem solving with large language models. *Advances in neural information processing systems*, **36**, pp.11809-11822.
    - Brynjolfsson, E., Li, D. and Raymond, L., 2025. Generative AI at work. *The Quarterly Journal of Economics*, p.qjae044.
    - Hinton, G., Vinyals, O. and Dean, J., 2015. Distilling the knowledge in a neural network. *arXiv preprint arXiv:1503.02531*.
    - Muennighoff, N., Yang, Z., Shi, W., Li, X.L., Fei-Fei, L., Hajishirzi, H., Zettlemoyer, L., Liang, P., Cand√®s, E. and Hashimoto, T., 2025. s1: Simple test-time scaling. *arXiv preprint arXiv:2501.19393*.
    - Park, J.S., O'Brien, J., Cai, C.J., Morris, M.R., Liang, P. and Bernstein, M.S., 2023, October. Generative agents: Interactive simulacra of human behavior. In *Proceedings of the 36th annual acm symposium on user interface software and technology* (pp. 1-22).
    - Ties de Kok (2025) ChatGPT for Textual Analysis? How to Use Generative LLMs in Accounting Research. *Management Science* forthcoming. [GitHub Link](https://github.com/TiesdeKok/chatgpt_paper)
    - Books, Notes, and Courses: Part 11 & 12 of [CS224N: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/cs224n/), [Talk @ Stanford by Barret Zoph and John Schulman](https://docs.google.com/presentation/d/11KWCKUORnPpVMSY6vXgBeFSWo7fJcuGQ9yuR6vC1pzE), Part 16 & 17 of [CS336: Large Language Models from Scratch](https://stanford-cs336.github.io/spring2024/index.html), Part 5, 6, 9 & 14 of [MIT 6.5940: TinyML and Efficient Deep Learning Computing](https://hanlab.mit.edu/courses/2024-fall-65940), [Berkeley LLM Agents](https://llmagents-learning.org/f24), [Finetuning LLMs](https://learn.deeplearning.ai/courses/finetuning-large-language-models), [Quantization Fundamentals](https://learn.deeplearning.ai/courses/quantization-fundamentals), [Building and Evaluating Advanced RAG](https://learn.deeplearning.ai/courses/building-evaluating-advanced-rag), [RLHF Short Course](https://learn.deeplearning.ai/courses/reinforcement-learning-from-human-feedback), Chatper 9 of [Scribed Notes for Spring 2024 Course Offering](https://github.com/rphilipzhang/AI-PhD-S24/blob/main/Notes/Scribed_Notes-AI-PhD-S24.pdf). [Handwritten Note](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Notes/250311.pdf).
    - Andrej Karpathy's Lectures: [Build GPT-2 (124M) from Scratch](https://www.youtube.com/watch?v=l8pRSuU81PU) [GitHub Repo for NanoGPT](https://github.com/karpathy/build-nanogpt/tree/master), [Deep Dive into LLM](https://www.youtube.com/watch?v=7xTGNNLPyMI), [How to Use LLM](https://www.youtube.com/watch?v=EWvNQjAaOHw), [Build the GPT Tokenizer](https://www.youtube.com/watch?v=zduSFxRajkE)
    - Miscellaneous Resources: [Video on DeepSeek R1](https://www.bilibili.com/video/BV1YGR8YUEEd/), [Video on DeekSeep MLA](https://www.bilibili.com/video/BV1HqFQezEMt/), [Approximating KL Divergence](http://joschu.net/blog/kl-approx.html), [DeepSeek Open-Infra Repo](https://github.com/deepseek-ai/open-infra-index), [Language Agents: Foundations, Prospects, and Risks (EMNLP 2024 Tutorial)](https://language-agent-tutorial.github.io/)

### üìö Session 9. Causal Inference Fundamentals (Mar/18/2025)
- üîë **Keywords**: Potential Outcomes Model, RCT, Unconfoundedness, IPW, AIPW
- üìä **Slides**: [What's New](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-0-WhatsNew.pdf), [What's Next](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-0.5-Announcement.pdf), [Causal Inference](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-10-Causal-RCT.pdf)
- üíª **CoLab Notebook Demos**: [Causal Inference under Unconfoundedness](https://colab.research.google.com/drive/1VD4a7EotCmAzYFAfCE3VJ3vOpCNvQm5P?usp=sharing)
- ‚úçÔ∏è **Homework**: [Problem Set 5: Bias and Variance with Mis-speficied Linear Regression](https://colab.research.google.com/drive/1VY3n7G4zF0Flgc1aDT9Tz4252QFScFgm?usp=sharing), due at 12:30pm, Apr/1/2025
- üìù **Presentation of Replication Project**: By Keming Li and Qilin Huang
    - Costello, T.H., Pennycook, G. and Rand, D.G., 2024. Durably reducing conspiracy beliefs through dialogues with AI. *Science*, 385(6714), p.eadq1814, [link to the paper](https://www.science.org/doi/10.1126/science.adq1814), [Replication Report, Code, and Slides](https://docs.google.com/spreadsheets/d/1ffRNlSFqki4vomz5UN0OseFNEoEXBY5kptS79wmgWs4/edit?gid=422252848#gid=422252848).
- üìö **References**:
    - Rubin, D.B., 1974. Estimating causal effects of treatments in randomized and nonrandomized studies. *Journal of educational Psychology*, 66(5), p.688.
    - Rosenbaum, P.R. and Rubin, D.B., 1983. The central role of the propensity score in observational studies for causal effects. *Biometrika*, 70(1), pp.41-55.
    - Li, F., Morgan, K.L. and Zaslavsky, A.M., 2018. Balancing covariates via propensity score weighting. *Journal of the American Statistical Association*, 113(521), pp.390-400.
    - Robins, J.M., Rotnitzky, A. and Zhao, L.P., 1994. Estimation of regression coefficients when some regressors are not always observed. *Journal of the American statistical Association*, 89(427), pp.846-866.
    - Books, Notes, and Courses: Chapters 1, 2, & 3 of [Causal Inference: A Statistical Learning Approach](https://web.stanford.edu/~swager/causal_inf_book.pdf), Chapters 2 & 5 of [Applied Causal Inference Powered by ML and AI](https://causalml-book.org/), Chapters 2 & 3 of [Duke STA 640: Causal Inference](https://www2.stat.duke.edu/~fl35/CausalInferenceClass.html), [Handwritten Note](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Notes/250318.pdf) 
    - Miscellaneous Resources: [Videos of Stanford ECON 293 Machine Learning and Causal Inference](https://www.youtube.com/playlist?list=PLxq_lXOUlvQAoWZEqhRqHNezS30lI49G-), [AEA Continuing Education on Machine Learning and Econometrics](https://www.aeaweb.org/conference/cont-ed/2018-webcasts)

### üìö Session 10. IPW, AIPW and DML (Mar/25/2025)
- üîë **Keywords**: IPW, AIPW, root-n consistency, DML
- üìä **Slides**: [What's New](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-0-WhatsNew.pdf), [What's Next](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-0.5-Announcement.pdf), [Causal Inference](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-10-Causal-RCT.pdf), [Double Machine Learning (*Incomplete*)](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-11-DML.pdf)
- üíª **CoLab Notebook Demos**: [Causal Inference under Unconfoundedness](https://colab.research.google.com/drive/1VD4a7EotCmAzYFAfCE3VJ3vOpCNvQm5P?usp=sharing), [IPW vs. AIPW](https://colab.research.google.com/drive/1FY9pPX_Rl4Lb1W7-XJNYwzbK5UT62a6u?usp=sharing)
- ‚úçÔ∏è **Homework**: [Problem Set 5: Bias and Variance with Mis-speficied Linear Regression](https://colab.research.google.com/drive/1VY3n7G4zF0Flgc1aDT9Tz4252QFScFgm?usp=sharing), due at 12:30pm, Apr/1/2025; [Problem Set 6: Double Machine Learning](https://colab.research.google.com/drive/1JApV5c4vqAHAzYESTtCUEABqAvA4-obg?usp=sharing), due at 12:30pm, Apr/8/2025
- üìù **Presentation of Replication Project**: By Zizhou Zhang and Lin Ma
    - Ye, Z., Zhang, Z., Zhang, D., Zhang, H. and Zhang, R.P., 2023. Deep-learning-based causal inference for large-scale combinatorial experiments: Theory and empirical evidence. *Management Science*, forthcoming. [Link to the Paper](https://rphilipzhang.github.io/rphilipzhang/DeDL-nonblind.pdf), [Link to the Code](https://github.com/zikunye2/deep_learning_based_causal_inference_for_combinatorial_experiments), [Replication Report, Code, and Slides](https://docs.google.com/spreadsheets/d/1ffRNlSFqki4vomz5UN0OseFNEoEXBY5kptS79wmgWs4/edit?gid=422252848#gid=422252848).
- üìö **References**:
    - Imbens, G. and Xu, Y., 2024. Lalonde (1986) after nearly four decades: Lessons learned. *arXiv preprint* arXiv:2406.00827. [Link to GitHub](https://github.com/xuyiqing/lalonde)
    - Rosenbaum, P.R. and Rubin, D.B., 1983. The central role of the propensity score in observational studies for causal effects. *Biometrika*, 70(1), pp.41-55.
    - Li, F., Morgan, K.L. and Zaslavsky, A.M., 2018. Balancing covariates via propensity score weighting. *Journal of the American Statistical Association*, 113(521), pp.390-400.
    - Robins, J.M., Rotnitzky, A. and Zhao, L.P., 1994. Estimation of regression coefficients when some regressors are not always observed. *Journal of the American statistical Association*, 89(427), pp.846-866.
    - Dud√≠k, M., Erhan, D., Langford, J. and Li, L., 2014. Doubly robust policy evaluation and optimization. *Statistical Science*, 29(4): 485-511.
    - Books, Notes, and Courses: Chapters 2, 3, 14 of [Causal Inference: A Statistical Learning Approach](https://web.stanford.edu/~swager/causal_inf_book.pdf), Chapters 2, 5 of [Applied Causal Inference Powered by ML and AI](https://causalml-book.org/), Chapters 2, 3 of [Duke STA 640: Causal Inference](https://www2.stat.duke.edu/~fl35/CausalInferenceClass.html), [Handwritten Note](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Notes/250325.pdf) 
    - Miscellaneous Resources: [Videos of Stanford ECON 293 Machine Learning and Causal Inference](https://www.youtube.com/playlist?list=PLxq_lXOUlvQAoWZEqhRqHNezS30lI49G-), [AEA Continuing Education on Machine Learning and Econometrics](https://www.aeaweb.org/conference/cont-ed/2018-webcasts), [DML Package](https://docs.doubleml.org/stable/index.html#), [Slides on DML](https://bstewart.scholar.princeton.edu/sites/g/files/toruqf4016/files/bstewart/files/chern.handout.pdf)

### üìö Session 11. Partial Linear Model and DML (Apr/1/2025)
- üîë **Keywords**: Doubly robust policy evaluation, partial linear model, FWL Theorem, DML
- üìä **Slides**: [What's New](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-0-WhatsNew.pdf), [What's Next](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-0.5-Announcement.pdf), [Causal Inference](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-10-Causal-RCT.pdf), [Double Machine Learning (*Incomplete*)](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-11-DML.pdf)
- üíª **CoLab Notebook Demos**: [FWL Theorem](https://colab.research.google.com/drive/1JNTyyr2w6D74rvJRiIxLu3gEfyTQqlH4?usp=sharing), [DML with EconML-ATE](https://colab.research.google.com/drive/1QKagJeZUgEgflTVwdM9lXVJhSiRvyhCD?usp=sharing), [DML with EconML-CATE](https://colab.research.google.com/drive/1K8kFCgZuW2kaGkz6aknRQkYhLJMAmI_g?usp=sharing), [EconML vs. DoubleML](https://colab.research.google.com/drive/1V_UuXNHRd1TiTds0-Gd2BsDYLkAoB4Sw?usp=sharing)
- ‚úçÔ∏è **Homework**: [Problem Set 6: Double Machine Learning](https://colab.research.google.com/drive/1JApV5c4vqAHAzYESTtCUEABqAvA4-obg?usp=sharing), due at 12:30pm, Apr/8/2025
- üìù **Presentation of Replication Project**: By Yiquan Chao and An Sheng
    - Ali Goli, Anja Lambrecht, Hema Yoganarasimhan (2023) A Bias Correction Approach for Interference in Ranking Experiments. *Marketing Science* 43(3):590-614. [Link to the Paper](https://pubsonline.informs.org/doi/10.1287/mksc.2022.0046), [Replication Report, Code, and Slides](https://docs.google.com/spreadsheets/d/1ffRNlSFqki4vomz5UN0OseFNEoEXBY5kptS79wmgWs4/edit?gid=422252848#gid=422252848).
- üìö **References**:
    - Robins, J.M., Rotnitzky, A. and Zhao, L.P., 1994. Estimation of regression coefficients when some regressors are not always observed. *Journal of the American statistical Association*, 89(427), pp.846-866.
    - Dud√≠k, M., Erhan, D., Langford, J. and Li, L., 2014. Doubly robust policy evaluation and optimization. *Statistical Science*, 29(4): 485-511.
    - Robinson P.M., 1988. Root-n-consistent semiparametric regression. *Econometrica*, Vol. 56, No. 4, pp. 931-954.
    - Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W. and Robins, J., 2018. Double/debiased machine learning for treatment and structural parameters. *The Econometrics Journal*, Volume 21, Issue 1, Pages C1‚ÄìC68.
    - Books, Notes, and Courses: Chapters 2, 3, 14 of [Causal Inference: A Statistical Learning Approach](https://web.stanford.edu/~swager/causal_inf_book.pdf), Chapters 2, 5, 9 of [Applied Causal Inference Powered by ML and AI](https://causalml-book.org/), Chapters 2, 3 of [Duke STA 640: Causal Inference](https://www2.stat.duke.edu/~fl35/CausalInferenceClass.html), Chapters 12, 22 of [Causal Inference for The Brave and True](https://matheusfacure.github.io/python-causality-handbook/landing-page.html), [Handwritten Note](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Notes/250401.pdf) 
    - Miscellaneous Resources: [Videos of Stanford ECON 293 Machine Learning and Causal Inference](https://www.youtube.com/playlist?list=PLxq_lXOUlvQAoWZEqhRqHNezS30lI49G-), [AEA Continuing Education on Machine Learning and Econometrics](https://www.aeaweb.org/conference/cont-ed/2018-webcasts), [DML Package](https://docs.doubleml.org/stable/index.html#), [Slides on DML](https://bstewart.scholar.princeton.edu/sites/g/files/toruqf4016/files/bstewart/files/chern.handout.pdf)

### üìö Session 12. DML: From Framework to Empirics (Apr/8/2025)
- üîë **Keywords**: DML, Neyman Orthogonality, Score Function, DML-DL, DML-DiD
- üìä **Slides**: [What's New](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-0-WhatsNew.pdf), [What's Next](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-0.5-Announcement.pdf), [Double Machine Learning](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-11-DML.pdf)
- üíª **CoLab Notebook Demos**: [DML with EconML-ATE](https://colab.research.google.com/drive/1QKagJeZUgEgflTVwdM9lXVJhSiRvyhCD?usp=sharing), [DML with EconML-CATE](https://colab.research.google.com/drive/1K8kFCgZuW2kaGkz6aknRQkYhLJMAmI_g?usp=sharing), [EconML vs. DoubleML](https://colab.research.google.com/drive/1V_UuXNHRd1TiTds0-Gd2BsDYLkAoB4Sw?usp=sharing), [DeDL](https://github.com/zikunye2/deep_learning_based_causal_inference_for_combinatorial_experiments/blob/main/synthetic_experiments.ipynb)
- ‚úçÔ∏è **Homework**: No coding homework this week. Please work on your final projects.
- üìù **Presentation of Replication Project**: By Mengyang Lin and Bingqi Zhang
    - Calvano, Emilio, Giacomo Calzolari, Vincenzo Denicol√≤, and Sergio Pastorello. 2020. "Artificial Intelligence, Algorithmic Pricing, and Collusion." *American Economic Review* 110 (10): 3267‚Äì97. [Link to the Paper](https://www.aeaweb.org/articles?id=10.1257/aer.20190623), [Replication Report, Code, and Slides](https://docs.google.com/spreadsheets/d/1ffRNlSFqki4vomz5UN0OseFNEoEXBY5kptS79wmgWs4/edit?gid=422252848#gid=422252848).
- üìö **References**:
    - Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W. and Robins, J., 2018. Double/debiased machine learning for treatment and structural parameters. *The Econometrics Journal*, Volume 21, Issue 1, Pages C1‚ÄìC68.
    - Brett R. Gordon, Robert Moakler, Florian Zettelmeyer (2022) Close Enough? A Large-Scale Exploration of Non-Experimental Approaches to Advertising Measurement. *Marketing Science* 42(4):768-793.
    - Farrell, M.H., Liang, T. and Misra, S., 2021. Deep neural networks for estimation and inference. *Econometrica*, 89(1), pp.181-213.
    - Farrell, M.H., Liang, T. and Misra, S., 2020. Deep learning for individual heterogeneity: An automatic inference framework. *arXiv preprint* arXiv:2010.14694.
    - Ye, Z., Zhang, Z., Zhang, D., Zhang, H. and Zhang, R.P., 2023. Deep-learning-based causal inference for large-scale combinatorial experiments: Theory and empirical evidence. *Management Science*, forthcoming.
    - Books, Notes, and Courses: Chapter 3 of [Causal Inference: A Statistical Learning Approach](https://web.stanford.edu/~swager/causal_inf_book.pdf), Chapter 9 of [Applied Causal Inference Powered by ML and AI](https://causalml-book.org/), Chapter 22 of [Causal Inference for The Brave and True](https://matheusfacure.github.io/python-causality-handbook/landing-page.html), [Handwritten Note](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Notes/250408.pdf) 
    - Miscellaneous Resources: [Videos of Stanford ECON 293 Machine Learning and Causal Inference](https://www.youtube.com/playlist?list=PLxq_lXOUlvQAoWZEqhRqHNezS30lI49G-), [AEA Continuing Education on Machine Learning and Econometrics](https://www.aeaweb.org/conference/cont-ed/2018-webcasts), [DML Package](https://docs.doubleml.org/stable/index.html#), [Slides on DML](https://bstewart.scholar.princeton.edu/sites/g/files/toruqf4016/files/bstewart/files/chern.handout.pdf), [Original Slides of Victor Chernozhukov](https://www.norges-bank.no/contentassets/f2cc0752a45b4a5f8fe7eead30c0a49e/chernozhukov_slides.pdf?v=04102017101451)

### üìö Session 13. Heterogeneous Treatment Effect (Apr/15/2025)
- üîë **Keywords**: HTE, Causal Tree, Causal Forest, Generalized Random Forest, Evaluation of HTE Estimation
- üìä **Slides**: [What's New](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-0-WhatsNew.pdf), [What's Next](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-0.5-Announcement.pdf), [Heterogeneous Treatment Effect](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-12-HTE.pdf), [Final Words](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Slides/AI-PhD-S2025-13-Final-Words.pdf)
- üíª **CoLab Notebook Demos**: [DML with EconML-CATE](https://colab.research.google.com/drive/1K8kFCgZuW2kaGkz6aknRQkYhLJMAmI_g?usp=sharing), [HTE with Causal Forest](https://colab.research.google.com/drive/1LsdUtlSHLiiIInO_jVav0EaMggFBho2A?usp=sharing)
- ‚úçÔ∏è **Homework**: [Problem Set 7: Heterogeneous Treatment Effect](https://colab.research.google.com/drive/1TvEPy3OzcxxP2jtX6IStOh-KDLuj032u?usp=sharing), due at 12:30pm, Apr/22/2025
- üìù **Presentation of Replication Project**: By Ningfan Lai and Yu Jiang
    - Moritz von Zahn, Kevin Bauer, Cristina Mihale-Wilson, Johanna Jagow, Maximilian Speicher, Oliver Hinz (2024) Smart Green Nudging: Reducing Product Returns Through Digital Footprints and Causal Machine Learning. *Marketing Science*, forthcoming.
 [Link to the Paper](https://pubsonline.informs.org/doi/10.1287/mksc.2022.0393), [Replication Report, Code, and Slides](https://docs.google.com/spreadsheets/d/1ffRNlSFqki4vomz5UN0OseFNEoEXBY5kptS79wmgWs4/edit?gid=422252848#gid=422252848).
- üìö **References**:
    - Athey, S. and Imbens, G., 2016. Recursive partitioning for heterogeneous causal effects. *Proceedings of the National Academy of Sciences*, 113(27), pp.7353-7360.
    - Wager, S. and Athey, S., 2018. Estimation and inference of heterogeneous treatment effects using random forests. *Journal of the American Statistical Association*, 113(523), pp.1228-1242.
    - Athey, S., Tibshirani, J. and Wager, S., 2019. Generalized random forests. *Annals of Statistics*. 47(2): 1148-1178 (April 2019).
    - Nie, X. and Wager, S., 2021. Quasi-oracle estimation of heterogeneous treatment effects. *Biometrika*, 108(2), pp.299-319.
    - K√ºnzel, S.R., Sekhon, J.S., Bickel, P.J. and Yu, B., 2019. Metalearners for estimating heterogeneous treatment effects using machine learning. *Proceedings of the national academy of sciences*, 116(10), pp.4156-4165.
    - Books, Notes, and Courses: Chapter 4 of [Causal Inference: A Statistical Learning Approach](https://web.stanford.edu/~swager/causal_inf_book.pdf), Chapters 14 & 15 of [Applied Causal Inference Powered by ML and AI](https://causalml-book.org/), Chapters 18 & 22 of [Causal Inference for The Brave and True](https://matheusfacure.github.io/python-causality-handbook/landing-page.html), Chapter 4 of [Stanford Causal Inference Tutorial](https://bookdown.org/stanfordgsbsilab/ml-ci-tutorial/hte-i-binary-treatment.html), [Handwritten Note](https://github.com/rphilipzhang/AI-PhD-S25/blob/main/Notes/250415.pdf) 
    - Miscellaneous Resources: Lectures 9-15 of [Videos of Stanford ECON 293 Machine Learning and Causal Inference](https://www.youtube.com/playlist?list=PLxq_lXOUlvQAoWZEqhRqHNezS30lI49G-), [AEA Continuing Education on Machine Learning and Econometrics](https://www.aeaweb.org/conference/cont-ed/2018-webcasts), [`grf` R Package](https://grf-labs.github.io/grf/), [Slides on GRF](https://math.bu.edu/BKT2023/slides/Shiraishi-slides.pdf)
